{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the Maze environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class maze():\n",
    "    '''\n",
    "    class to define a maze of arbitrary size, with hurdles in between \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, size = 4):\n",
    "        self.size=size\n",
    "        self.board = np.zeros((size, size))\n",
    "        \n",
    "        mvlist = []\n",
    "        for i in range(size):\n",
    "            for j in range(size):\n",
    "                mvlist.append((i,j))\n",
    "        self.movelist = mvlist\n",
    "        self.allmoves = self.movelist\n",
    "        \n",
    "        self.start = (0,0)\n",
    "        self.end = (size-1, size-1)\n",
    "        #print (self.end)\n",
    "        self.agent_pos = self.start\n",
    "        self.actions = ['N', 'E', 'S', 'W']\n",
    "    \n",
    "    def set_blocks(self, blocklist):\n",
    "        '''\n",
    "        function to define hurdles/closed cells\n",
    "        '''\n",
    "        mlist = self.movelist\n",
    "        nlist = []\n",
    "        \n",
    "        for mm in mlist:\n",
    "            if (mm in blocklist):\n",
    "                pass\n",
    "            else:\n",
    "                nlist.append(mm)\n",
    "                \n",
    "        self.movelist = nlist     \n",
    "            \n",
    "    def move(self, step):\n",
    "        '''\n",
    "        function to move the agent by the given step. if a step takes the agent out of the maze, \n",
    "        that step is not executed\n",
    "        '''\n",
    "        orow,ocol = self.agent_pos\n",
    "        \n",
    "        row,col = self.agent_pos\n",
    "        \n",
    "        #print (row, col)\n",
    "        if (step == 'N'):\n",
    "            row -= 1\n",
    "        elif (step =='E'):\n",
    "            col += 1\n",
    "        elif (step == 'S'):\n",
    "            row += 1\n",
    "        elif (step == 'W'):\n",
    "            col -= 1\n",
    "            \n",
    "        #print (row, col)\n",
    "        \n",
    "        reward = -0.1        \n",
    "        if ((row,col) in self.movelist):\n",
    "            reward = -(abs(row-self.end[0]) + abs(col-self.end[1]))\n",
    "        else:\n",
    "            reward = -100\n",
    "            row, col = orow, ocol\n",
    "            \n",
    "        # update agent position\n",
    "        self.agent_pos = (row,col)\n",
    "        \n",
    "        return (reward)       \n",
    "    \n",
    "    def print_board(self, fname='Test.png', count=0, move=0,reward=0):\n",
    "        '''\n",
    "        function to print board, to visualise agent movement\n",
    "        '''\n",
    "        agent_position = self.agent_pos\n",
    "        fields = list(self.allmoves)\n",
    "        movelist = list(self.movelist)\n",
    "        #blockedmoves = list(self.blocklist)\n",
    "        size = self.size\n",
    "        nfields = len(fields)\n",
    "        board = \"-----------------\\n\"\n",
    "\n",
    "        for i in range(0, nfields, size):\n",
    "            line = fields[i:i+size]\n",
    "            for field in line:\n",
    "                if field == agent_position:\n",
    "                    board += \"| A \"\n",
    "                elif field == fields[0]:\n",
    "                    board += \"| S \"\n",
    "                elif field == fields[-1]:\n",
    "                    board += \"| E \"\n",
    "                elif field not in movelist:\n",
    "                    board += \"| X \"\n",
    "                else:\n",
    "                    board += \"|   \"\n",
    "            board += \"|\\n\"\n",
    "            board += \"-----------------\\n\"     \n",
    "        #print(board)\n",
    "        #plt.rc('figure', figsize=(12, 7))\n",
    "        stepstr = 'step:' + str(count)\n",
    "        movestr = 'move:' + str(move)\n",
    "        rewardstr = 'reward:' + str(reward)\n",
    "        #plt.clf()\n",
    "        plt.close('all')\n",
    "        plt.rc('figure', figsize=(4,4))\n",
    "        plt.text(0.15, 0.9, str(stepstr), {'fontsize': 10}, fontproperties = 'monospace') # approach improved by OP -> monospace!\n",
    "        plt.text(0.45, 0.9, str(movestr), {'fontsize': 10}, fontproperties = 'monospace') # approach improved by OP -> monospace!\n",
    "        plt.text(0.25, 0.8, str(rewardstr), {'fontsize': 10}, fontproperties = 'monospace') # approach improved by OP -> monospace!\n",
    "        plt.text(0.1, 0.1, str(board), {'fontsize': 10}, fontproperties = 'monospace') # approach improved by OP -> monospace!\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(fname)\n",
    "        return ()\n",
    "    \n",
    "    ##############################################################################################################\n",
    "    ## functions for reinforcement learning\n",
    "    def state(self):\n",
    "        '''\n",
    "        function to return agent position, for use in the Q learning table\n",
    "        '''\n",
    "        return (self.agent_pos)\n",
    "    \n",
    "    def setpos(self, pos):\n",
    "        '''\n",
    "        function to set the starting position of agent at different locations\n",
    "        '''\n",
    "        self.agent_pos = pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Board = maze()\n",
    "print ('Agent position is at', Board.agent_pos)\n",
    "\n",
    "Board.set_blocks([(1,1), (2,1), (0,3)])\n",
    "print (\"move list is\", Board.movelist)\n",
    "\n",
    "if (0,1) in Board.movelist:\n",
    "    print ('Yes')\n",
    "    \n",
    "print (Board.agent_pos) \n",
    "Board.move('S')\n",
    "\n",
    "Board.print_board()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "######### Functions used\n",
    "######################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement learning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Board = maze(size=4)\n",
    "print (Board.agent_pos)\n",
    "#print (Board.board)\n",
    "print (Board.actions)\n",
    "Board.print_board()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=Board.size\n",
    "actions = Board.actions\n",
    "nactions = len(actions)\n",
    "print (size, nactions)\n",
    "print (actions)\n",
    "alpha = 0.5\n",
    "gamma = 0.1\n",
    "epsilon = 1.0\n",
    "\n",
    "##################################################################################\n",
    "## Declare the q table as an array of size (n X n) where n is the size of the maze\n",
    "## State is the location of agent (i,j) in the Qtable\n",
    "## actions are 4 movements, N, E, W, and S\n",
    "\n",
    "def initQtable():\n",
    "    Q = np.zeros((size, size, nactions))\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            for k in range(nactions):\n",
    "                Q[i,j,k] = 0.001 * np.random.random()\n",
    "    print ('Shape of Q table is', np.shape(Q))\n",
    "    return (Q)\n",
    "    \n",
    "def retbestact(Qtable, state):\n",
    "    '''\n",
    "    Qtable: as declared above, is a np array\n",
    "    state: comes from enviornment is a tuple with three values\n",
    "    '''\n",
    "    #print (state)\n",
    "    maxval = np.max(Qtable[state])\n",
    "    argmax = np.argmax(Qtable[state])\n",
    "    \n",
    "    return (maxval, argmax)\n",
    "\n",
    "##################################################################################\n",
    "## Function to return action - based on greedy epsilon\n",
    "def chooseaction(Qtable, state):\n",
    "    #print ('Hello')\n",
    "\n",
    "    maxval, argmax = retbestact(Qtable, state)\n",
    "    #bestact = actions[argmax]\n",
    "    \n",
    "    ### If random number greater than epsion, choose exploitaiton\n",
    "    ### else, choose exploration\n",
    "    if (np.random.random() > epsilon):\n",
    "        bestact = actions[argmax]\n",
    "        flag = 'best'\n",
    "    else:\n",
    "        bestact = np.random.choice(actions)\n",
    "        flag = 'random' \n",
    "    return (bestact)\n",
    "\n",
    "### Test the RL functions\n",
    "Q = initQtable()\n",
    "\n",
    "## Test the return best action function\n",
    "#Q[2,1,3] = 5\n",
    "#Q[2,1,0] = 15\n",
    "\n",
    "retbestact(Q, (2,1))\n",
    "\n",
    "## Test the choose action function\n",
    "chooseaction(Q, (2,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize the board\n",
    "Board = maze(size=4)\n",
    "Board.set_blocks([(1,1), (2,0), (0,3)])\n",
    "print (Board.movelist)\n",
    "\n",
    "## set up highest epsilon, for exploration\n",
    "epsilon=1\n",
    "print (epsilon)\n",
    "\n",
    "## count steps in each direction\n",
    "movecounter = {'N':0, 'E':0, 'S':0, 'W':0}\n",
    "## count number of steps\n",
    "count = 0\n",
    "\n",
    "# Q table\n",
    "Q = initQtable()\n",
    "\n",
    "a = list(Board.movelist)\n",
    "print (Board.print_board())\n",
    "\n",
    "#location\n",
    "currstate = Board.state()\n",
    "#print (currstate)\n",
    "\n",
    "for i in range(10000):\n",
    "    \n",
    "    # choose a step to move\n",
    "    mve = chooseaction(Q, currstate)\n",
    "    movecounter[mve] += 1\n",
    "    # get the reward for the move and make the move\n",
    "    reward = Board.move(mve)\n",
    "\n",
    "    newstate = Board.state()\n",
    "    #print (newstate)\n",
    "\n",
    "    maxval, argmax = retbestact(Q, newstate)\n",
    "\n",
    "    nextmaxre  = argmax\n",
    "\n",
    "    #print ('nextmaxreward', nextmaxre)\n",
    "\n",
    "    loc = (currstate[0], currstate[1], actions.index(mve))\n",
    "\n",
    "    Q[loc] += alpha * (reward + gamma * nextmaxre - Q[loc])\n",
    "    \n",
    "    currstate = newstate\n",
    "\n",
    "    count += 1\n",
    "print ('total steps', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movecounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the trained agent movement - Exploitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Board = maze(size=4)\n",
    "Board.set_blocks([(1,1), (2,0), (0,3)])\n",
    "epsilon = 0\n",
    "ll = []\n",
    "\n",
    "fname='Step-00.png'\n",
    "print (fname)\n",
    "Board.print_board(fname = fname, count = 0, move = '')\n",
    "    \n",
    "for i in range(10):\n",
    "    currstate = Board.state()\n",
    "    if (currstate == (3,3)):\n",
    "        break\n",
    "    mve = chooseaction(Q, currstate)\n",
    "    Board.move(mve)\n",
    "    print (currstate, mve)\n",
    "    fname='Step-' + str(i+1).zfill(2) + '.png'\n",
    "    print (fname)\n",
    "    Board.print_board(fname = fname, count = i+1, move = mve)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
