{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbf4335f-4332-4698-a7a9-49d09bb9ee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75721967-642c-4758-8e37-e24cf4d162d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(tn, fp, fn, tp):\n",
    "    total = tn + fp + fn + tp\n",
    "    accuracy = (tn + tp)/total\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp + fn)\n",
    "    return (accuracy, precision, recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b9a761-b1bb-4376-8bb3-12b4383faee5",
   "metadata": {},
   "source": [
    "# 01 - Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3fa3797-cd90-47ee-83db-f426eab4a4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "negative    50\n",
       "positive    50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data source: Kaggle - https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
    "df_original = pd.read_csv('data/01-IMDB Dataset.csv')\n",
    "# Sample 1K each positive and negative reviews\n",
    "df = df_original.groupby('sentiment').sample(n=50, random_state=1).reset_index(drop=True)\n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe35e10-baa0-4d7e-8ffc-59e80b47f0ad",
   "metadata": {},
   "source": [
    "## 02 - Sample Sentiment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4d274e6-7a0d-458c-83e5-ef7ec83fb85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input string list\n",
    "s1 = \"The food was great!\"\n",
    "s2 = \"This is the worst movie I ever saw\"\n",
    "s3 = \"This food is no less than many good restaurants in town\"\n",
    "s4 = \"I don't understand why people rated this as a good movie. There is nothing worth talking about\"\n",
    "strlst = [s1,s2, s3,s4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "096ab1ff-8dd6-44a1-b0a5-10695ee5f91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The food was great! >> Sentiment(polarity=1.0, subjectivity=0.75)\n",
      "This is the worst movie I ever saw >> Sentiment(polarity=-1.0, subjectivity=1.0)\n",
      "This food is no less than many good restaurants in town >> Sentiment(polarity=0.42777777777777776, subjectivity=0.3888888888888889)\n",
      "I don't understand why people rated this as a good movie. There is nothing worth talking about >> Sentiment(polarity=0.5, subjectivity=0.35000000000000003)\n"
     ]
    }
   ],
   "source": [
    "# TextBlob\n",
    "from textblob import TextBlob\n",
    "\n",
    "for i in range(len(strlst)):\n",
    "  tst = TextBlob(strlst[i])\n",
    "  print(tst, \">>\", tst.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75903e9-427b-44a4-a570-8a517721e456",
   "metadata": {},
   "source": [
    "# 03 - Evaluate Sentiment using TextBlob and return evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3ef6a00-2073-47a9-97d7-a3028d8ceaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Sentiment and Polarity for reviews\n",
    "df['Polarity'] = df['review'].apply(lambda x: TextBlob(x).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "272063f8-3671-4c91-acce-a1a11e8fc3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Polarity'].describe()\n",
    "meanscore = df['Polarity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88e19540-ab0b-43d7-89cc-670f51085fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predicted_sentiment'] = df['Polarity'].apply(lambda x: 'positive' if x > meanscore else 'negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9103b2d7-9523-4e77-be57-50bf352f78e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I recently viewed Manufactured Landscapes at t...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.323333</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I figured that any horror film with Orson Well...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.001535</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run away from this movie. Even by B-movie stan...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.048963</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oh dear. I was so disappointed that this movie...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.020536</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Below average blaxpoitation action / melodrama...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.248276</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  Polarity  \\\n",
       "0  I recently viewed Manufactured Landscapes at t...  negative  0.323333   \n",
       "1  I figured that any horror film with Orson Well...  negative  0.001535   \n",
       "2  Run away from this movie. Even by B-movie stan...  negative -0.048963   \n",
       "3  Oh dear. I was so disappointed that this movie...  negative  0.020536   \n",
       "4  Below average blaxpoitation action / melodrama...  negative  0.248276   \n",
       "\n",
       "  predicted_sentiment  \n",
       "0            positive  \n",
       "1            negative  \n",
       "2            negative  \n",
       "3            negative  \n",
       "4            positive  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f82a9e9-c8d8-4e36-ae15-e0fc2a42482f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33, 17],\n",
       "       [15, 35]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfmt = confusion_matrix(df['sentiment'], df['predicted_sentiment'], labels=['positive', 'negative'])\n",
    "cfmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f58a63d5-9ee9-4f91-ba15-86b3f6c661ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35, 15],\n",
       "       [17, 33]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfmt = confusion_matrix(df['sentiment'], df['predicted_sentiment'], labels=['negative', 'positive'])\n",
    "cfmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2990714-8b80-4562-bfd2-0c0357742059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 15, 17, 33)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = cfmt.ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206e3104-594a-48a2-9390-b01d87c128fa",
   "metadata": {},
   "source": [
    "# 04 -Evaluate sentiment with different models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b892ea2-ba85-43e3-a0cb-43ce7c97f38a",
   "metadata": {},
   "source": [
    "## 04 - 01 - Text Blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "168d1517-41e0-4e11-9215-2203ab7d7022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text blob sentiment analyzer\n",
      "accuracy, precision and recall are 0.68 0.6875 0.66\n"
     ]
    }
   ],
   "source": [
    "def textblob_sentiment(df_inp):\n",
    "    print ('text blob sentiment analyzer')\n",
    "    df = df_inp.copy()\n",
    "    df['textblob_polarity'] = df['review'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "    meanscore = df['textblob_polarity'].mean()\n",
    "    df['predicted_sentiment'] = df['textblob_polarity'].apply(lambda x: 'positive' if x > meanscore else 'negative')\n",
    "    cfmt = confusion_matrix(df['sentiment'], df['predicted_sentiment'], labels=['negative', 'positive'])\n",
    "    tn, fp, fn, tp = cfmt.ravel()\n",
    "    acc, pre, rec = eval_metrics(tn, fp, fn, tp)\n",
    "    print ('accuracy, precision and recall are', acc, pre, rec)\n",
    "    return \n",
    "\n",
    "textblob_sentiment(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862ce118-0974-4125-ba2f-9e8ceae7c40c",
   "metadata": {},
   "source": [
    "# 04 - 02 - Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21c13cb5-b9bb-4dff-9e60-c20670fdfd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vader sentiment analyzer\n",
      "accuracy, precision and recall are 0.65 0.6027397260273972 0.88\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def vader_S(text):\n",
    "    vs = analyzer.polarity_scores(text)\n",
    "    if (vs['neg'] > vs['pos']):\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'positive'  \n",
    "\n",
    "def vader_sentiment(df_inp):\n",
    "    print ('vader sentiment analyzer')\n",
    "    df = df_inp.copy()\n",
    "    df['vader_sentiment'] = df['review'].apply(lambda x: vader_S(x))\n",
    "    cfmt = confusion_matrix(df['sentiment'], df['vader_sentiment'], labels=['negative', 'positive'])\n",
    "    tn, fp, fn, tp = cfmt.ravel()\n",
    "    acc, pre, rec = eval_metrics(tn, fp, fn, tp)\n",
    "    print ('accuracy, precision and recall are', acc, pre, rec)\n",
    "    return \n",
    "\n",
    "vader_sentiment(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e27774-c162-42a1-9aa3-4bb0e5242d68",
   "metadata": {},
   "source": [
    "## 04 - 03 - Sentence Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b5f8de9-f3e3-4fbd-b553-075c35e9303f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsrivallabha/VirtualEnvs/NLP/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "#pip install transformers\n",
    "from transformers import pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68227401-2e23-4318-96b1-833afc5cf32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline(strlst[0])[0]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59cb9d70-d7e4-435c-819b-536b8435f38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, precision and recall are 0.875 0.8837209302325582 0.8636363636363636\n"
     ]
    }
   ],
   "source": [
    "#pip install transformers\n",
    "def trf_s(x):\n",
    "    try:    \n",
    "        y = sentiment_pipeline(x)\n",
    "        #print (y)\n",
    "        return (y[0]['label'])\n",
    "    except:\n",
    "        return 'none'\n",
    "\n",
    "\n",
    "def transformer_sentiment(df_inp):\n",
    "    df = df_inp.copy()\n",
    "    df['transformer_sentiment'] = df['review'].apply(lambda x: trf_s(x).lower())\n",
    "    cfmt = confusion_matrix(df['sentiment'], df['transformer_sentiment'], labels=['negative', 'positive'])\n",
    "    tn, fp, fn, tp = cfmt.ravel()\n",
    "    acc, pre, rec = eval_metrics(tn, fp, fn, tp)\n",
    "    print ('accuracy, precision and recall are', acc, pre, rec)\n",
    "    return \n",
    "\n",
    "transformer_sentiment(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f968a32a-7714-460e-a329-ad21d612e669",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
