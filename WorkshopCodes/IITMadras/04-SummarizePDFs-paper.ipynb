{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOGzSzO/tvblDNHP7hjpaAb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-cbObgdxtfyA","executionInfo":{"status":"ok","timestamp":1728960051312,"user_tz":-330,"elapsed":9309,"user":{"displayName":"Sri Vallabha Deevi","userId":"16579142413712204940"}},"outputId":"d31f1295-e96f-4ddc-b144-5a56b117d6ac"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\n","Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.4.1+cu121)\n","Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.24.7)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"]}],"source":["!pip install PyPDF2\n","!pip install einops\n","!pip install accelerate"]},{"cell_type":"markdown","source":["# Summarize research papers from arxiv"],"metadata":{"id":"O_wi_xMPxTrZ"}},{"cell_type":"code","source":["from PyPDF2 import PdfReader"],"metadata":{"id":"D11yUJScxWUy","executionInfo":{"status":"ok","timestamp":1728960058799,"user_tz":-330,"elapsed":732,"user":{"displayName":"Sri Vallabha Deevi","userId":"16579142413712204940"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["file_path = '/content/2403.04121v2.pdf'"],"metadata":{"id":"JNnQMFyAxYK5","executionInfo":{"status":"ok","timestamp":1728960058799,"user_tz":-330,"elapsed":2,"user":{"displayName":"Sri Vallabha Deevi","userId":"16579142413712204940"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# Read the PDF in binary mode\n","with open(file_path, 'rb') as file:\n","    pdf_reader = PdfReader(file)\n","    text = \"\"\n","\n","    # Extract text from each page\n","    for page_num in range(len(pdf_reader.pages)):\n","        page = pdf_reader.pages[page_num]\n","        text += page.extract_text()"],"metadata":{"id":"nZDXoVItxZop","executionInfo":{"status":"ok","timestamp":1728960059500,"user_tz":-330,"elapsed":4,"user":{"displayName":"Sri Vallabha Deevi","userId":"16579142413712204940"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["print (text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b_59gZrNxdR4","executionInfo":{"status":"ok","timestamp":1728960064809,"user_tz":-330,"elapsed":575,"user":{"displayName":"Sri Vallabha Deevi","userId":"16579142413712204940"}},"outputId":"09a152de-c5e4-466b-dc31-f0f5564edb1d"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Can Large Language Models Reason and Plan?\n","Subbarao Kambhampati\n","School of Computing & Augmented Intelligence\n","Arizona State University\n","email: rao@asu.edu\n","A version appears in the Annals of The New York Academy of Sciences:\n","https://nyaspubs.onlinelibrary.wiley.com/doi/10.1111/nyas.15125\n","Large Language Models (LLMs), essentially n-gram mod-\n","els on steroids *that have been trained on web-scale lan-\n","guage corpora (or, effectively, our civilizational knowl-\n","edge), have caught our collective imagination with linguis-\n","tic behaviors that no one expected text completion systems\n","to possess3. By training and operation, LLMs are perhaps\n","best seen as giant non-veridical memories akin to an ex-\n","ternal System 12for us all (see Figure 1). Their seem-\n","ing versatility has however led many researchers to wonder\n","whether they can also do well on planning and reasoning\n","tasks typically associated with System 2 competency.\n","Nothing in the training and use of LLMs would seem\n","to suggest remotely that they can do any type of princi-\n","pled reasoning (which, as we know, often involves com-\n","putationally hard inference/search). What LLMs are good\n","at is a form of universal approximate retrieval. Unlike\n","databases that index and retrieve data exactly, LLMs, as n-\n","gram models, probabilistically reconstruct completions for\n","the prompt word by word–a process we shall refer to as\n","approximate retrieval . This means that LLMs can’t even\n","guarantee memorizing complete answers, something that\n","is the flip side of their appeal about constructing “novel”\n","prompt completions on the fly. The boon (“creativity”) and\n","bane (“hallucination”) of LLMs is that n-gram models will\n","naturally mix and match–and have almost as much trouble\n","strictly memorizing as we do. It is indeed the very basis of\n","their appeal.\n","*LLMs are trained to predict the distribution of the n-th to-\n","ken given n-1 previous tokens. GPT3.5 that powered the origi-\n","nal ChatGPT is, for example, a roughly 3001-gram model of lan-\n","guage.\n","Figure 1. An informal account of viewing LLM as a giant external\n","non-veridical memory that acts as a pseudo System 1\n","Despite this, the “Large Language Models are Zero-Shot\n","⟨insert-your-reasoning-task ⟩” has almost become a meme\n","paper title! At some level, this trend is perhaps inevitable as\n","in the era of LLMs, AI has become a form of ersatz natural\n","science5–driven by observational studies of capabilities of\n","these behemoth systems.\n","So, are these n-gram models on steroids really capable of\n","planning and reasoning? In the summer of 2022, when my\n","research group wanted to better answer this question, most\n","reasoning claims were still somewhat anecdotal. So, we set\n","out to evaluate GPT3 on a set of planning instances derived\n","from the domains typically used in the International Plan-\n","ning Competition (IPC) –including the well known Blocks\n","World†. Our results13were contrary to the anecdotal claims\n","about the planning abilities of LLMs, and when we made\n","them public, received significant attention in the AI circles.\n","By the beginning of 2023, with the wide-spread public re-\n","†https://en.wikipedia.org/wiki/Blocks world\n","1arXiv:2403.04121v2  [cs.AI]  8 Mar 2024lease of ChatGPT, and later, GPT4, there were a slew of ad-\n","ditional claims, including in refereed papers, about LLM’s\n","abilities to reason and plan. So we decided to repeat our\n","tests on both GPT3.5 and GPT412. Initial results showed\n","that there was some improvement in the accuracy of gen-\n","erated plans from GPT3 to GPT3.5 to GPT4, with GPT4\n","reaching 30% empirical accuracy in the Blocks World (al-\n","beit still lower in other domains). We then wanted to know\n","whether the modest improvement is because of the im-\n","proved approximate retrieval abilities or whether GPT4 is\n","actually doing/searching for plans.\n","Let us pause to note that my interest here is not whether\n","LLMs can fake reasoning (by giving correct answers to\n","reasoning tasks from memory and pattern finding), but\n","whether they can actually do principled reasoning. Of\n","course, seeing patterns in reasoning problems is not any-\n","thing to be sneezed at. After all, our interest in master-\n","ing it is what is behind much of “street fighting” math\n","(e.g. George P ´olya’s ”How to Solve it”). But finding ap-\n","proximate shortcuts over provably correct reasoning proce-\n","dures is obviously not equivalent to doing reasoning–unless\n","you have an ability to establish from first principles that\n","your hunch is actually correct. It is challenging to decide\n","whether a system (or a human, for that matter) is memoriz-\n","ing or solving a problem from scratch–especially as the sys-\n","tems (or humans) get trained on larger and larger “question\n","banks.” This is a challenge that most instructors and inter-\n","viewers are acutely aware of. Think of that infamous “Why\n","are manhole covers round?” interview question. While it\n","may well have given the interviewer an insight into the\n","candidate’s analytical reasoning skills the very first time it\n","was asked, all it does with high probability now is to con-\n","firm whether the candidate trained on the interview ques-\n","tion banks!\n","Considering that the LLMs don’t suffer some of the nor-\n","mal limitations of humans–such as having a life on the\n","side, and thus not having the time or inclination to focus\n","exclusively on the test/interview preparation for long peri-\n","ods, they can support approximate retrieval over webscale\n","corpora. My research group wanted to check if the im-\n","proved performance of GPT4 is because of approximate re-\n","trieval from a larger training corpus, or really comes from\n","its ability to plan. One way of checking this for planning\n","tasks is to reduce the effectiveness of approximate retrievalby obfuscating the names of the actions and objects in the\n","planning problem. When we did this for test domains12,11,\n","GPT4’s empirical performance plummeted precipitously,\n","despite the fact that none of the standard off-the-shelf AI\n","planners have any trouble with such obfuscation.‡\n","Perhaps they can’t do planning autonomously straight out\n","of the box, but can they do it with a little nudge? There\n","are broadly two popular techniques for such nudging. The\n","first, called “fine tuning,” is rather straightforward: take a\n","general LLM and fine tune it on planning problems (i.e.,\n","instances and their solutions), with the hope that they will\n","subsequently make better guesses (see the left-hand side\n","of Figure 1). While our own limited experiments didn’t\n","show any significant improvement through fine tuning, it\n","is possible that with even more fine tuning data and ef-\n","fort, the quality of LLM guesses may well improve. But\n","all that such fine tuning is doing is converting the planning\n","task into a memory-based approximate retrieval (akin to the\n","memorization/compilation from System 2 to System 1; see\n","Figure 1). It doesn’t prove that LLMs are able to plan.\n","The second way to improve planning (and reasoning) per-\n","formance is to prompt an LLM back with hints/suggestions\n","about how it can improve its initial plan guess. The crucial\n","questions here are (a) whether this back prompting is man-\n","ual or automated (b) who is certifying the correctness of the\n","final answer and (c) whether the prompts inject additional\n","problem knowledge or are just merely exhorting the LLM\n","to try again.\n","The cleanest approach–one we advocate12,6–is to let an ex-\n","ternal model-based plan verifier do the back prompting and\n","to certify the correctness of the final solution. In general,\n","such LLM-Modulo frameworks6can gainfully leverage the\n","amazing idea generation capabilities of LLMs with sound\n","external verifiers in a generate-test-critique framework with\n","gurantees.\n","In contrast, by far the more popular methodology is to\n","have the human in the loop prompt the LLM iteratively.\n","The problem with this is that it is highly susceptible to the\n","‡As these results came about at the height of sparks of\n","AGI/existential risk angst, we couldn’t resist the tongue-in-cheek\n","editorializing that if GPT4 ever goes rogue, you can stymie it by\n","throwing a simple planning problem at it! Humor aside, nothing\n","in our studies showed that GPT4 is capable of generating exe-\n","cutable plans autonomously.\n","2Figure 2. Claimed reasoning capabilities of LLMs are sometimes\n","due to the subconscious helpful iterative prompting by the humans\n","in the loop (graphic adapted from https://xkcd.com/2347/ under\n","Creative Commons License)\n","Clever Hans effect§, where the LLM is merely generating\n","guesses, and it is the human in the loop, with the knowledge\n","of right vs. wrong solutions, who is steering the LLM–even\n","if they didn’t set out to do so deliberately. The credit and\n","blame for the ensuring accuracy, if any, falls squarely on\n","the human in the loop. The relevance of such a frame-\n","work becomes questionable when the human-in-the-loop\n","doesn’t know (or is unable to verify) the answer to the rea-\n","soning/planning problem themselves. Thus the tongue-in-\n","cheek characterization of LLM reasoning abilities in Fig-\n","ure 2.\n","A variation on the second approach is to have the LLM it-\n","self “critique” the guesses it generates and iteratively self-\n","improve. Although some papers seem to swear by such a\n","“self-improvement” capability of LLMs, the plausibility of\n","such a claim hinges on the belief that the LLMs are bet-\n","ter at verifying their solutions than they are at generating\n","them. While never explicitly justified, the assumption rests\n","§https://en.wikipedia.org/wiki/Clever Hanson either analogies to humans or indirect nods to compu-\n","tational complexity arguments. While humans sometimes\n","do show the capability of correcting their own erroneous\n","guesses with self-critiquing, there seems to be no basis for\n","that assumption in the case of LLMs. And while for many\n","computational tasks (e.g. those in class NP¶), the verifica-\n","tion is often of lower complexity than generation, that fact\n","doesn’t seem particularly relevant for LLMs which are gen-\n","erating (approximately retrieving) guesses, rather than ac-\n","tually solving the problem with guarantees. Indeed two re-\n","cent studies from my lab–one on plan verification10and the\n","other on constraint verification9–seem to throw cold water\n","on this optimism by showing that with “self-verification”\n","performance actually worsens. This is because LLMs hal-\n","lucinate both false positives and false negatives while ver-\n","ifying the solutions they generate. One reason this is not\n","recognized in earlier literature is that there self-verification\n","claims are often made in the context of tacit knowledge\n","tasks for which there is little possibility of a verifier (e.g.\n","writing/improving essays), making it harder to evaluate\n","whether LLM’s critiquing actually helped. Paradoxically,\n","the fact that it is infeasible to write sound verifiers for tacit\n","knowledge tasks also makes it easier to mistake LLMs for\n","being as reasonable a critic as any!||In other cases, an ex-\n","ternal simulator winds up playing the role of sound verifi-\n","cation.\n","While the foregoing questions the claims that LLMs are\n","capable of planning/reasoning, it is not meant to imply that\n","LLMs don’t have any constructive roles to play in solving\n","planning/reasoning tasks. In particular, their uncanny abil-\n","ity to generate ideas/potential candidate solutions–albeit\n","with no guarantees about those guesses–can still be valu-\n","able in the “LLM-Modulo” setups6, in conjunction with\n","either model-based verifiers or expert humans in the loop.\n","The trick to avoiding ascribing autonomous reasoning ca-\n","pabilities to LLMs is to recognize that LLMs are generating\n","potential answers that still need to be checked by external\n","verifiers.\n","The skeptical reader might now ask: But what about all\n","¶NP stands for nondeterministic polynomial , and covers the\n","class of computational problems whose solutions can be verified\n","in polynomial time.\n","||In other words, LLMs can be as good as that Peloton instruc-\n","tor in confidently critiquing Christopher Nolan movies.\n","3those papers at high profile AI conferences that claim to\n","show planning abilities of LLMs? To analyze those claims,\n","we need to first understand that solving planning tasks re-\n","quires (a) having the necessary planning domain knowl-\n","edge–the actions and their preconditions, effects; the stan-\n","dard hierarchical recipes (e.g. task reduction schemas in\n","Hierarchical Task Network planning), past cases/plans etc.\n","and (b) being able to assemble this knowledge into an ex-\n","ecutable plan that takes care of any subgoal/resource inter-\n","actions. The first can be called the knowledge acquisition\n","part, and the second reasoning/planning part. Many of the\n","papers claiming planning abilities of LLMs, on closer ex-\n","amination, wind up confusing general planning knowledge\n","extracted from the LLMs for executable plans. When all we\n","are looking for are abstract plans, such as “wedding plans,”\n","with no intention of actually executing said plans directly,\n","it is easy to confuse them for complete executable plans.\n","Indeed, our close examination of several papers claiming\n","planning capabilities7for LLMs suggests that they either\n","are evaluating in domains/tasks where subgoal interactions\n","can be safely ignored, or delegating the interaction resolu-\n","tion (reasoning) to the humans in the loop (who, through\n","repeated prompting, have to “correct” the plan). Some-\n","times, in common sense domains, or with enough fine tun-\n","ing, the “assembling” part may also be obviated by having\n","seen a case that pretty much corresponds to the problem\n","that needs to be solved. Without these assumptions or mit-\n","igations, the plans that come out of LLMs may look rea-\n","sonable to the lay user, but lead to execution time interac-\n","tions and errors. These issues are illustrated in part by a\n","recent news story about the proliferation of travel planning\n","books8, mostly auto-extracted from LLMs, and the ensu-\n","ing disappointment of the unsuspecting end users who buy\n","them mistaking them for usable plans!\n","The fact that LLMs are often good at extracting planning\n","knowledge can indeed be gainfully leveraged. As we have\n","argued in recent work1, LLMs can be a rich source of\n","approximate models of world/domain dynamics and user\n","preferences, as long as the humans (and any specialized\n","critics) in the loop verify and refine the models, and give\n","them over to model-based solvers. This way of using LLMs\n","has the advantage that the humans need only be present\n","when the dynamics/preference model is being teased out\n","and refined, with the actual planning after that being left to\n","sound frameworks with correctness guarantees6.\n","Figure 3. Viewing LLMs as an approximate knowledge source\n","trained over civilizational knowledge\n","Such a framework has striking similarities to knowledge-\n","based AI systems of yore, with LLMs effectively replac-\n","ing the “knowledge engineer” (Figure 3). Given the rather\n","quixotic and dogmatic shift of AI away from approaches\n","that accept domain knowledge from human experts, some-\n","thing I bemoaned in “ P´olanyi’s revenge and AI’s new ro-\n","mance with tacit knowledge ”4this new trend of using\n","LLMs as knowledge sources can be viewed as a form of\n","avenging Polanyi’s revenge (by bringing explicit knowl-\n","edge back to AI systems, if only as gleaned from LLMs). **\n","Indeed, LLMs make it easy to get problem-specific knowl-\n","edge, as long as we are willing to relax correctness require-\n","ments of that knowledge. In contrast to the old knowledge\n","engineering approaches, LLMs offer this without making it\n","look like we are inconveniencing any specific human (we\n","are, instead, just leveraging everything humans have told\n","each other!). So the million dollar question for reasoning\n","tasks becomes: “how would you do planning if you have\n","some doddering know-it-all ready to give you any kind of\n","knowledge?” The LLM-Modulo framework6is a princi-\n","pled method for tackling this challenge.\n","To summarize, nothing that I have read, verified, or done\n","gives me any compelling reason to believe that LLMs do\n","reasoning/planning, as normally understood. What they do\n","instead, armed with web-scale training, is a form of uni-\n","versal approximate retrieval, which, as I have argued, can\n","**There is rich irony here: If you give what you know about\n","a toy world to the computer, and have it solve new instances, it\n","would be derisively called “Good Old Fashioned AI,” but if you\n","capture all that the humanity knows about everything (as exported\n","to the Internet), train your LLM on it, and then ask it to provide\n","approximate task relevant knowledge, then it becomes “modern\n","AI.”\n","4sometimes be mistaken for reasoning capabilities. LLMs\n","do excel in idea generation for any task–including those\n","involving reasoning, and as I pointed out, this can be ef-\n","fectively leveraged to support reasoning/planning in LLM-\n","Modulo frameworks6. In other words, LLMs already have\n","enough amazing approximate retrieval abilities that can be\n","gainfully leveraged, that we don’t need to ascribe question-\n","able reasoning/planning capabilities to them.††\n","References\n","[1] Lin Guan, Karthik Valmeekam, Sarath Sreedharan,\n","and Subbarao Kambhampati. Leveraging pre-trained\n","large language models to construct and utilize world\n","models for model-based task planning. In Thirty-\n","seventh Conference on Neural Information Process-\n","ing Systems , 2023.\n","[2] Daniel Kahneman. Thinking, fast and slow . macmil-\n","lan, 2011.\n","[3] Subbarao Kambhampati. Language imitation games\n","and the arrival of broad and shallow AI. CACM Blog ,\n","2021.\n","[4] Subbarao Kambhampati. Polanyi’s revenge and AI’s\n","new romance with tacit knowledge. Communications\n","of the ACM , 64(2):31–32, 2021.\n","[5] Subbarao Kambhampati. AI as (an ersatz) natural sci-\n","ence? Communications of the ACM , 65(9):8–9, 2022.\n","[6] Subbarao Kambhampati, Karthik Valmeekam, Lin\n","Guan, Kaya Stechly, Mudit Verma, Siddhant Bham-\n","bri, Lucas Saldyt, and Anil Murthy. LLMs can’t plan,\n","but can help planning in LLM-Modulo frameworks.\n","arXiv preprint 2402.01817 , 2024.\n","[7] Subbarao. Kambhampati, Karthik. Valmeekam,\n","Matthew. Marquez, and Lin. Guan. On the role\n","††Although we focused on planning and reasoning tasks, the\n","discussion here has implications to LLM-based code generation.\n","There too, while LLMs can help as “co-pilots” to human pro-\n","grammers, there is never any guarantee that the code they gen-\n","erate is correct. The fact that code generation capabilities come\n","fromgithub data, that is of higher quality than the general web\n","data, and the fact that incremental interpreters in the loop can pin-\n","point any syntax errors in the generated code, helps the utility of\n","the suggested code snippets for human programmers.of large language models in planning, July 2023.\n","Tutorial presented at the International Conference\n","on Automated Planning and Scheduling (ICAPS),\n","Prague.\n","[8] Seth Kugel and Stephen Hiltner. A new frontier for\n","travel scammers: A.I.-Generated Guidebooks. New\n","York Times , August 2023.\n","[9] Kaya Stechly, Matthew Marquez, and Subbarao\n","Kambhampati. GPT-4 Doesn’t Know It’s Wrong: An\n","Analysis of Iterative Prompting for Reasoning Prob-\n","lems. In NeurIPS 2023 Foundation Models for Deci-\n","sion Making Workshop , 2023.\n","[10] Karthik Valmeekam, Matthew Marquez, and Sub-\n","barao Kambhampati. Can large language models re-\n","ally improve by self-critiquing their own plans? In\n","NeurIPS 2023 Foundation Models for Decision Mak-\n","ing Workshop , 2023.\n","[11] Karthik Valmeekam, Matthew Marquez, Alberto\n","Olmo, Sarath Sreedharan, and Subbarao Kambham-\n","pati. Planbench: An extensible benchmark for evalu-\n","ating large language models on planning and reason-\n","ing about change. In Thirty-seventh Conference on\n","Neural Information Processing Systems Datasets and\n","Benchmarks Track , 2023.\n","[12] Karthik Valmeekam, Matthew Marquez, Sarath\n","Sreedharan, and Subbarao Kambhampati. On the\n","planning abilities of large language models - a crit-\n","ical investigation. In Thirty-seventh Conference on\n","Neural Information Processing Systems , 2023.\n","[13] Karthik Valmeekam, Alberto Olmo, Sarath Sreedha-\n","ran, and Subbarao Kambhampati. Large language\n","models still can’t plan (a benchmark for llms on plan-\n","ning and reasoning about change). arXiv preprint\n","arXiv:2206.10498 , 2022.\n","5\n"]}]},{"cell_type":"code","source":["print (len(text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j8SfeMwXxeiF","executionInfo":{"status":"ok","timestamp":1728960068026,"user_tz":-330,"elapsed":460,"user":{"displayName":"Sri Vallabha Deevi","userId":"16579142413712204940"}},"outputId":"80a2ef5e-3559-4fc1-ba3d-e627d41e98f7"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["19864\n"]}]},{"cell_type":"markdown","source":["# Large Paper Summarization Model"],"metadata":{"id":"o0FUUOr0_dzG"}},{"cell_type":"code","source":["# Ref: https://huggingface.co/com3dian/Bart-large-paper2slides-summarizer\n","from transformers import BartTokenizer, BartForConditionalGeneration, pipeline\n","\n","# Load the model and tokenizer\n","model_name = \"com3dian/Bart-large-paper2slides-summarizer\"\n","tokenizer = BartTokenizer.from_pretrained(model_name)\n","model = BartForConditionalGeneration.from_pretrained(model_name)"],"metadata":{"id":"cCy8y8j__giq","executionInfo":{"status":"ok","timestamp":1728960072564,"user_tz":-330,"elapsed":2362,"user":{"displayName":"Sri Vallabha Deevi","userId":"16579142413712204940"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["paper_summary = \" \"\n","for i in range(10):\n","  print ('loop', i)\n","  start = i * 2000\n","  end = (i+1) * 2000\n","\n","  # Generate summary from input text\n","  input_text = text[start:end]\n","  input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n","  output = model.generate(input_ids)\n","\n","  # Decode generated summaries\n","  summary = tokenizer.decode(output[0], skip_special_tokens=True)\n","  paper_summary += summary\n","  paper_summary += '\\n'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IuWQIoNl_l-z","executionInfo":{"status":"ok","timestamp":1728960319595,"user_tz":-330,"elapsed":244309,"user":{"displayName":"Sri Vallabha Deevi","userId":"16579142413712204940"}},"outputId":"79332a28-dd9a-4eaa-ba4c-514f9ed12cce"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["loop 0\n","loop 1\n","loop 2\n","loop 3\n","loop 4\n","loop 5\n","loop 6\n","loop 7\n","loop 8\n","loop 9\n"]}]},{"cell_type":"code","source":["print (paper_summary)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xfVTDtWhADYF","executionInfo":{"status":"ok","timestamp":1728960325703,"user_tz":-330,"elapsed":478,"user":{"displayName":"Sri Vallabha Deevi","userId":"16579142413712204940"}},"outputId":"8e3e3999-21e8-4b2f-f07c-b57fb60db51e"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":[" Can Large Language Models Reason and Plan?Subbarao Kambhampati School of Computing & Augmented Intelligence, Arizona State University. The Large Language Model (LLMs) probabilistically reconstruct completions for the prompt word by word. LLMs can't even guarantee memorizing complete answers, which is the flip side of their appeal.\n","nt of viewing LLM as a giant external external non-veridical memory that acts as a pseudo System 1 System 1. Despite this, the “Large Language Models are Zero-Shot Zero- shot Zero-shot Zero- Shot Zero Zero ZeroZero-ShotZeroZeroZero-shotZeroZero ZeroZeroZero zeroZeroZerozeroZero Zero Zero zero Zero Zerozero Zero Zero  LLM    [cs.AI]  8 Mar 2024 [cscs. AI] [cs AI] 8 Mar 2403.04121v2 [csAI] [CS.AI], [csLSI]  [CSLSi] 8 March 2024 (cs.\n","Finding ap-proximate shortcuts over provably correct reasoning proce-                dures is obviously not equivalent to doing reasoning–unless you have an ability to establish from first principles that your hunch is actually correct. It is challenging to decide whether a system (or a human, for that matter) is memoriz-iably solving a problem from scratch.\n","? There are broadly two popular techniques for nudging LLMs to make better guesses. The first is to take a general LLM and fine tune it on planning problems (i.e., their solutions) The second is to prompt an LLM back with hints/suggestions about how to improve its initial plan guess.\n","T4 is capable of generating exe-                cutable plans autonomously. Claimed reasoning capabilities of LLMs are sometimes due to the subconscious helpful iterative prompting by the humans in the loop. The relevance of such a frame-work becomes questionable when the human-in-the-loop doesn't know the answer to the rea-                soning/planning problem themselves.\n","em to throw cold water on optimism by showing that with “self-verification” performance actually worsens. This is because LLMs hal-lucinate both false positives and false negatives while ver-ifying the solutions they generate. In other cases, an ex-ternal simulator winds up playing the role of sound verifi-                cation. It is not meant to imply that LLMs don’t have any constructive roles to play in solving planning tasks.\n","in knowl-edge–the actions and their preconditions, effects; the stan-                dard hierarchical recipes (e.g. task reduction schemas in hierarchical Task Network planning), past cases/plans etc. and (b) being able to assemble this knowledge into an ex-                ecutable plan that takes care of any subgoal/resource inter-actions. Many of the papers claiming planning abilities of LLMs wind up confusing general planning knowledge from LLMs for executable plans. LLMs can be a rich source ofroximate models of world/domain dynamics.\n","LLM-Modulo framework is a way of using LLMs as approximate knowledge source trained over civilizational civilizational Civilizational Civilization Civilizational Criticics (c.ny specializedcritics) in the loop verify and refine the models, and give them over to model-based solvers. This way has striking similarities to knowledge-based AI systems of yore, with LLMs effectively replac-replacing the “knowledge engineer” (Figure 3)\n","ve it solve new instances, it would be derisively called “Good Old Fashioned AI,” but if you capture all that humanity knows about everything (as exported exportedto the Internet), train your LLM on it, then it becomes “modern modern AI” LLMs excel in idea generation for any task, and can be ef-fectively leveraged to support reasoning/planning in LLM-Modulo frameworks6.\n","code they gen-erate is correct. The fact that incremental interpreters in the loop can pin-point any syntax errors in the generated code, helps the utility of the suggested code snippets for human programmers. GPT-4 Doesn’t Know It’s Wrong: AnAnalysis of Iterative Prompting for Reasoning Prob-lems.\n","\n"]}]},{"cell_type":"code","source":["lines = paper_summary.split('\\n')"],"metadata":{"id":"PdFaqUZJBJTQ","executionInfo":{"status":"ok","timestamp":1728960339530,"user_tz":-330,"elapsed":463,"user":{"displayName":"Sri Vallabha Deevi","userId":"16579142413712204940"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["len(lines)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cICAlZpMERl0","executionInfo":{"status":"ok","timestamp":1728960346413,"user_tz":-330,"elapsed":450,"user":{"displayName":"Sri Vallabha Deevi","userId":"16579142413712204940"}},"outputId":"5f217a99-ecfb-450b-ea97-80020399d047"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["11"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["for i in range(11):\n","  print ('\\n')\n","  print (lines[i])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nw0abyJXETSe","executionInfo":{"status":"ok","timestamp":1728960381303,"user_tz":-330,"elapsed":454,"user":{"displayName":"Sri Vallabha Deevi","userId":"16579142413712204940"}},"outputId":"146a9dff-de54-4c85-d723-7955d8719d8f"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n"," Can Large Language Models Reason and Plan?Subbarao Kambhampati School of Computing & Augmented Intelligence, Arizona State University. The Large Language Model (LLMs) probabilistically reconstruct completions for the prompt word by word. LLMs can't even guarantee memorizing complete answers, which is the flip side of their appeal.\n","\n","\n","nt of viewing LLM as a giant external external non-veridical memory that acts as a pseudo System 1 System 1. Despite this, the “Large Language Models are Zero-Shot Zero- shot Zero-shot Zero- Shot Zero Zero ZeroZero-ShotZeroZeroZero-shotZeroZero ZeroZeroZero zeroZeroZerozeroZero Zero Zero zero Zero Zerozero Zero Zero  LLM    [cs.AI]  8 Mar 2024 [cscs. AI] [cs AI] 8 Mar 2403.04121v2 [csAI] [CS.AI], [csLSI]  [CSLSi] 8 March 2024 (cs.\n","\n","\n","Finding ap-proximate shortcuts over provably correct reasoning proce-                dures is obviously not equivalent to doing reasoning–unless you have an ability to establish from first principles that your hunch is actually correct. It is challenging to decide whether a system (or a human, for that matter) is memoriz-iably solving a problem from scratch.\n","\n","\n","? There are broadly two popular techniques for nudging LLMs to make better guesses. The first is to take a general LLM and fine tune it on planning problems (i.e., their solutions) The second is to prompt an LLM back with hints/suggestions about how to improve its initial plan guess.\n","\n","\n","T4 is capable of generating exe-                cutable plans autonomously. Claimed reasoning capabilities of LLMs are sometimes due to the subconscious helpful iterative prompting by the humans in the loop. The relevance of such a frame-work becomes questionable when the human-in-the-loop doesn't know the answer to the rea-                soning/planning problem themselves.\n","\n","\n","em to throw cold water on optimism by showing that with “self-verification” performance actually worsens. This is because LLMs hal-lucinate both false positives and false negatives while ver-ifying the solutions they generate. In other cases, an ex-ternal simulator winds up playing the role of sound verifi-                cation. It is not meant to imply that LLMs don’t have any constructive roles to play in solving planning tasks.\n","\n","\n","in knowl-edge–the actions and their preconditions, effects; the stan-                dard hierarchical recipes (e.g. task reduction schemas in hierarchical Task Network planning), past cases/plans etc. and (b) being able to assemble this knowledge into an ex-                ecutable plan that takes care of any subgoal/resource inter-actions. Many of the papers claiming planning abilities of LLMs wind up confusing general planning knowledge from LLMs for executable plans. LLMs can be a rich source ofroximate models of world/domain dynamics.\n","\n","\n","LLM-Modulo framework is a way of using LLMs as approximate knowledge source trained over civilizational civilizational Civilizational Civilization Civilizational Criticics (c.ny specializedcritics) in the loop verify and refine the models, and give them over to model-based solvers. This way has striking similarities to knowledge-based AI systems of yore, with LLMs effectively replac-replacing the “knowledge engineer” (Figure 3)\n","\n","\n","ve it solve new instances, it would be derisively called “Good Old Fashioned AI,” but if you capture all that humanity knows about everything (as exported exportedto the Internet), train your LLM on it, then it becomes “modern modern AI” LLMs excel in idea generation for any task, and can be ef-fectively leveraged to support reasoning/planning in LLM-Modulo frameworks6.\n","\n","\n","code they gen-erate is correct. The fact that incremental interpreters in the loop can pin-point any syntax errors in the generated code, helps the utility of the suggested code snippets for human programmers. GPT-4 Doesn’t Know It’s Wrong: AnAnalysis of Iterative Prompting for Reasoning Prob-lems.\n","\n","\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"1r4f_CyqEZaX"},"execution_count":null,"outputs":[]}]}