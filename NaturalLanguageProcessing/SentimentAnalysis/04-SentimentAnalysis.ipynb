{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data set source: http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "'''\n",
    "@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
    "  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
    "  title     = {Learning Word Vectors for Sentiment Analysis},\n",
    "  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
    "  month     = {June},\n",
    "  year      = {2011},\n",
    "  address   = {Portland, Oregon, USA},\n",
    "  publisher = {Association for Computational Linguistics},\n",
    "  pages     = {142--150},\n",
    "  url       = {http://www.aclweb.org/anthology/P11-1015}\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the files and preparing the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readallcomments(path, flag):\n",
    "    fl = os.listdir(path)\n",
    "    print (len(fl))\n",
    "    ll = []\n",
    "    for f in fl:\n",
    "        ff = path  + f\n",
    "        strr = open(ff, 'r').read()\n",
    "        ll.append([flag, strr])\n",
    "    \n",
    "    lldf = pd.DataFrame(ll)\n",
    "    lldf.columns = ['Rating', 'Comment']    \n",
    "    return (lldf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos = './aclImdb_v1/aclImdb/train/pos/'\n",
    "train_neg = './aclImdb_v1/aclImdb/train/neg/'\n",
    "\n",
    "test_pos = './aclImdb_v1/aclImdb/test/pos/'\n",
    "test_neg = './aclImdb_v1/aclImdb/test/neg/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainposdf = readallcomments(train_pos, '1')\n",
    "print (len(trainposdf))\n",
    "print (trainposdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainnegdf = readallcomments(train_neg, '0')\n",
    "print (len(trainnegdf))\n",
    "print (trainnegdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = trainposdf.append(trainnegdf)\n",
    "print (len(traindf))\n",
    "traindf.to_csv('TrainingData.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testposdf = readallcomments(test_pos, '1')\n",
    "print (len(testposdf))\n",
    "print (testposdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testnegdf = readallcomments(test_neg, '0')\n",
    "print (len(testnegdf))\n",
    "print (testnegdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = testposdf.append(testnegdf)\n",
    "print (len(testdf))\n",
    "testdf.to_csv('TestingData.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 100\n",
    "print (traindf.iloc[i].Rating)\n",
    "print (traindf.iloc[i].Comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 24999\n",
    "print (testdf.iloc[i].Rating)\n",
    "print (testdf.iloc[i].Comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textclean(text):\n",
    "    text = text.lower()\n",
    "    symblst = ['<', '*', '?', '>', \"\\\\\", \"\\'\", \"\\\"\", ',']\n",
    "    for s in symblst:\n",
    "        text = text.replace(s,'')\n",
    "    #text = text.replace('  ', ' ')\n",
    "    text = ' '.join(text.split())\n",
    "        \n",
    "    return (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'This is a > sample comment quote < \\\\ hello , the movie is worst ? *'\n",
    "textclean(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform each text into a vector of word counts\n",
    "vectorizer = CountVectorizer(stop_words=\"english\",\n",
    "                             preprocessor=textclean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsents  = ['A cat is walking in the rain', 'Dog running on a sunny day']\n",
    "vectorizer.fit(trainsents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the vectorizer's vocabulary\n",
    "inv_vocab = {v: k for k, v in vectorizer.vocabulary_.items()}\n",
    "vocabulary = [inv_vocab[i] for i in range(len(inv_vocab))]\n",
    "print (vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsents = ['rain on a sunny day, and a dog and an elephant are walking']\n",
    "pd.DataFrame(data=vectorizer.transform(testsents).toarray(),\n",
    "    index=[\"test sentence\"],\n",
    "    columns=vocabulary\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the vectorizer on IMDB ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = vectorizer.fit_transform(traindf[\"Comment\"])    \n",
    "test_features = vectorizer.transform(testdf[\"Comment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "model0 = LinearSVC()\n",
    "model0.fit(training_features, traindf[\"Rating\"])\n",
    "y_pred = model0.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "acc = accuracy_score(testdf[\"Rating\"], y_pred)\n",
    "print(\"Accuracy on the IMDB dataset: {:.2f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rating(samplerating, vectorizer, model):\n",
    "    sr = [samplerating]\n",
    "    test_features = vectorizer.transform(sr)\n",
    "    ypred = model.predict(test_features)\n",
    "    #print (ypred)\n",
    "    return (ypred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c0 = 'This is the worst movie I have ever seen. Wonder why I statyed till the end'\n",
    "get_rating(c0, model0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = 'This is a very nicely made movie. I liked the editiing'\n",
    "get_rating(c1,  model0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3 = 'this is a not so good movie'\n",
    "get_rating(c3, model0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the model - Another approach - Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform each text into a vector of word counts\n",
    "vectorizer1 = TfidfVectorizer(stop_words=\"english\",\n",
    "                             preprocessor=textclean,\n",
    "                             ngram_range=(1, 2))\n",
    "\n",
    "training_features = vectorizer1.fit_transform(traindf[\"Comment\"])    \n",
    "test_features = vectorizer1.transform(testdf[\"Comment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "model1 = LinearSVC()\n",
    "model1.fit(training_features, traindf[\"Rating\"])\n",
    "y_pred = model1.predict(test_features)\n",
    "\n",
    "# Evaluation\n",
    "acc = accuracy_score(testdf[\"Rating\"], y_pred)\n",
    "\n",
    "print(\"Accuracy on the IMDB dataset: {:.2f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3 = 'this movie is so so'\n",
    "get_rating(c3, vectorizer, model0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3 = 'this movie is so so'\n",
    "get_rating(c3, vectorizer1, model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
